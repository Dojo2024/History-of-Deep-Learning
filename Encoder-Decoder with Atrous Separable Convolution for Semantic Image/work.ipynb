{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b968586",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SeparableConv2d(nn.Module):\n",
    "    \"\"\"\n",
    "    Implements a depthwise separable convolution block as used in Xception.\n",
    "    This class factorizes a standard convolution into a depthwise convolution\n",
    "    followed by a pointwise convolution.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1, dilation=1, bias=False):\n",
    "        \"\"\"\n",
    "        Initializes the depthwise separable convolution module.\n",
    "\n",
    "        Args:\n",
    "            in_channels (int): Number of input channels.\n",
    "            out_channels (int): Number of output channels.\n",
    "            kernel_size (int): Size of the depthwise kernel. Default: 3.\n",
    "            stride (int): Stride of the depthwise convolution. Default: 1.\n",
    "            padding (int): Padding for the depthwise convolution. Default: 1.\n",
    "            dilation (int): Dilation rate for the depthwise convolution. Default: 1.\n",
    "            bias (bool): Whether to include bias terms. Default: False.\n",
    "        \"\"\"\n",
    "        super(SeparableConv2d, self).__init__()\n",
    "\n",
    "        # --- Depthwise Convolution ---\n",
    "        # Applies a spatial filter to each input channel independently.\n",
    "        self.depthwise = nn.Conv2d(\n",
    "            in_channels, \n",
    "            in_channels,          # Output channels == Input channels\n",
    "            kernel_size=kernel_size, \n",
    "            stride=stride, \n",
    "            padding=padding, \n",
    "            dilation=dilation,\n",
    "            groups=in_channels,   # This is the key to making it depthwise\n",
    "            bias=bias\n",
    "        )\n",
    "\n",
    "        # --- Pointwise Convolution ---\n",
    "        # A 1x1 convolution to mix the channels from the depthwise step.\n",
    "        self.pointwise = nn.Conv2d(\n",
    "            in_channels, \n",
    "            out_channels, \n",
    "            kernel_size=1, \n",
    "            stride=1, \n",
    "            padding=0, \n",
    "            dilation=1,\n",
    "            bias=bias\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Defines the forward pass of the separable convolution.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): The input tensor of shape [B, C_in, H, W].\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The output tensor of shape [B, C_out, H', W'].\n",
    "        \"\"\"\n",
    "        # First, apply the depthwise convolution to capture spatial patterns\n",
    "        x = self.depthwise(x)\n",
    "        # Second, apply the pointwise convolution to mix channels\n",
    "        x = self.pointwise(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c65567e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Assuming the SeparableConv2d class from Step 1 is already defined above this code)\n",
    "\n",
    "class Block(nn.Module):\n",
    "    \"\"\"\n",
    "    Defines a single Xception block.\n",
    "    This block consists of a series of depthwise separable convolutions\n",
    "    and a residual connection.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, reps, stride=1, start_with_relu=True, grow_first=True):\n",
    "        \"\"\"\n",
    "        Initializes the Xception Block.\n",
    "\n",
    "        Args:\n",
    "            in_channels (int): Number of input channels.\n",
    "            out_channels (int): Number of output channels.\n",
    "            reps (int): Number of separable convolution repetitions within the block.\n",
    "            stride (int): Stride for the first convolution in the block, used for downsampling.\n",
    "            start_with_relu (bool): Whether to apply a ReLU activation before the first conv.\n",
    "            grow_first (bool): If True, the first separable conv changes the number of channels,\n",
    "                               otherwise the last one does.\n",
    "        \"\"\"\n",
    "        super(Block, self).__init__()\n",
    "\n",
    "        # --- Residual Connection Path ---\n",
    "        # This is for the 'shortcut' or 'identity' path.\n",
    "        # It's needed if the main path changes dimensions (stride > 1) or channels.\n",
    "        if out_channels != in_channels or stride != 1:\n",
    "            self.skip = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "        else:\n",
    "            self.skip = None\n",
    "\n",
    "        # --- Main Convolutional Path ---\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        # Build the sequence of separable convolutions for the main path\n",
    "        rep_layers = []\n",
    "        \n",
    "        # Determine which layer will handle the channel growth\n",
    "        current_channels = in_channels\n",
    "        if grow_first:\n",
    "            rep_layers.append(self.relu)\n",
    "            rep_layers.append(SeparableConv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False))\n",
    "            rep_layers.append(nn.BatchNorm2d(out_channels))\n",
    "            current_channels = out_channels\n",
    "\n",
    "        # Add the rest of the repetitions\n",
    "        for i in range(reps - 1):\n",
    "            rep_layers.append(self.relu)\n",
    "            rep_layers.append(SeparableConv2d(current_channels, current_channels, kernel_size=3, stride=1, padding=1, bias=False))\n",
    "            rep_layers.append(nn.BatchNorm2d(current_channels))\n",
    "        \n",
    "        # Apply striding and potential channel growth in the last layer if not done first\n",
    "        if not grow_first:\n",
    "            rep_layers.append(self.relu)\n",
    "            rep_layers.append(SeparableConv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False))\n",
    "            rep_layers.append(nn.BatchNorm2d(out_channels))\n",
    "        \n",
    "        # The first layer in the sequence may have a stride for downsampling\n",
    "        if stride != 1:\n",
    "            # The logic to apply stride to the first convolution of the sequence\n",
    "            # Note: This is a simplified logic. In the original Xception, the striding layer is more explicitly defined.\n",
    "            # Here we ensure the very first conv in the block gets the stride if needed.\n",
    "            # A more direct implementation as per the paper:\n",
    "            # The first SeparableConv2d in the block would take the stride argument. We will refine this.\n",
    "            pass # Placeholder for more complex stride logic if needed. Our current logic is a simplification.\n",
    "\n",
    "        # The Xception paper has a specific structure where the first layer of the block\n",
    "        # may have stride != 1. Let's refine the logic to be more faithful.\n",
    "        \n",
    "        # --- Refined Main Path Logic ---\n",
    "        self.reps = reps\n",
    "        self.start_with_relu = start_with_relu\n",
    "        \n",
    "        # The first layer of the block handles potential downsampling (stride)\n",
    "        if grow_first:\n",
    "            # First layer expands channels, then subsequent layers are same-channel\n",
    "            first_conv_out_channels = out_channels\n",
    "            self.conv1 = SeparableConv2d(in_channels, first_conv_out_channels, 3, stride=stride, padding=1, bias=False)\n",
    "            self.bn1 = nn.BatchNorm2d(first_conv_out_channels)\n",
    "            \n",
    "            # Subsequent layers\n",
    "            self.convs = nn.ModuleList()\n",
    "            self.bns = nn.ModuleList()\n",
    "            for i in range(reps-1):\n",
    "                self.convs.append(SeparableConv2d(first_conv_out_channels, first_conv_out_channels, 3, stride=1, padding=1, bias=False))\n",
    "                self.bns.append(nn.BatchNorm2d(first_conv_out_channels))\n",
    "        else:\n",
    "            # All but the last layer are same-channel, last layer expands\n",
    "            self.convs = nn.ModuleList()\n",
    "            self.bns = nn.ModuleList()\n",
    "            for i in range(reps-1):\n",
    "                self.convs.append(SeparableConv2d(in_channels, in_channels, 3, stride=1 if i > 0 else stride, padding=1, bias=False))\n",
    "                self.bns.append(nn.BatchNorm2d(in_channels))\n",
    "            \n",
    "            # Last layer\n",
    "            self.conv_last = SeparableConv2d(in_channels, out_channels, 3, stride=1, padding=1, bias=False)\n",
    "            self.bn_last = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Defines the forward pass for the Xception block.\n",
    "        \"\"\"\n",
    "        residual = x\n",
    "\n",
    "        # --- Main Path ---\n",
    "        # First layer with potential ReLU start\n",
    "        if self.start_with_relu:\n",
    "            x = self.relu(x)\n",
    "        \n",
    "        # Apply the sequence of convolutions\n",
    "        # (This is a simplified forward pass based on the refined logic)\n",
    "        # Proper forward pass would iterate through the ModuleList of convs and bns.\n",
    "        # Let's write the correct, more modular forward pass.\n",
    "\n",
    "        # Correct Forward Pass:\n",
    "        if self.skip is not None:\n",
    "            residual = self.skip(residual)\n",
    "        \n",
    "        # Let's revert to a simpler, more readable implementation for teaching purposes.\n",
    "        # The complex `grow_first` logic can be abstracted away by how we call the block.\n",
    "        # We will create a list of layers and pass the input through them sequentially.\n",
    "        \n",
    "        # --- FINAL, CLEAN IMPLEMENTATION for Step 2 ---\n",
    "        # We will remove the complex `grow_first` logic from the constructor\n",
    "        # and instead define the block as a simpler sequence, which is easier to understand.\n",
    "        \n",
    "        # (Re-writing the class for clarity)\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, dilation=1):\n",
    "        super(Block, self).__init__()\n",
    "\n",
    "        # --- Residual Connection Path ---\n",
    "        # This handles the case where the input dimensions (channels or spatial size)\n",
    "        # need to be changed to match the output dimensions for the final addition.\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.skip = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "        else:\n",
    "            self.skip = None\n",
    "\n",
    "        # --- Main Convolutional Path ---\n",
    "        # The main path in an Xception block typically consists of:\n",
    "        # ReLU -> SeparableConv -> BN -> ReLU -> SeparableConv -> BN ...\n",
    "        # The first convolution in the block is responsible for any downsampling (stride > 1).\n",
    "        self.conv_path = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            SeparableConv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=dilation, dilation=dilation, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            SeparableConv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=dilation, dilation=dilation, bias=False),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # --- Residual Path ---\n",
    "        if self.skip is not None:\n",
    "            skip_x = self.skip(x)\n",
    "        else:\n",
    "            skip_x = x\n",
    "\n",
    "        # --- Main Path ---\n",
    "        main_x = self.conv_path(x)\n",
    "        \n",
    "        # --- Add Residual ---\n",
    "        output = main_x + skip_x\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "625a4b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Assuming SeparableConv2d and Block classes are defined above)\n",
    "\n",
    "class Xception(nn.Module):\n",
    "    \"\"\"\n",
    "    Implements the modified Xception backbone for DeepLabv3+.\n",
    "    The architecture is modified to allow for atrous convolution to control\n",
    "    the output stride, which is crucial for semantic segmentation.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels=3, output_stride=16):\n",
    "        \"\"\"\n",
    "        Initializes the Xception backbone.\n",
    "\n",
    "        Args:\n",
    "            in_channels (int): Number of input channels, typically 3 for RGB images.\n",
    "            output_stride (int): The ratio of input image spatial resolution to the final\n",
    "                                 output feature map spatial resolution. Must be 8 or 16.\n",
    "        \"\"\"\n",
    "        super(Xception, self).__init__()\n",
    "\n",
    "        # --- Set up stride and dilation rates based on output_stride ---\n",
    "        if output_stride == 16:\n",
    "            entry_block3_stride = 2\n",
    "            middle_block_dilation = 1\n",
    "            exit_block_dilations = (1, 2)\n",
    "        elif output_stride == 8:\n",
    "            entry_block3_stride = 1\n",
    "            middle_block_dilation = 2\n",
    "            exit_block_dilations = (2, 4)\n",
    "        else:\n",
    "            raise ValueError(\"Output stride must be 8 or 16.\")\n",
    "\n",
    "        # ================== ENTRY FLOW ==================\n",
    "        # First two convolutions are standard, not separable\n",
    "        self.conv1 = nn.Conv2d(in_channels, 32, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        # The entry flow consists of 3 blocks\n",
    "        self.block1 = Block(in_channels=64, out_channels=128, stride=2)\n",
    "        self.block2 = Block(in_channels=128, out_channels=256, stride=2)\n",
    "        # The stride of this block depends on the desired output_stride\n",
    "        self.block3 = Block(in_channels=256, out_channels=728, stride=entry_block3_stride)\n",
    "\n",
    "        # ================== MIDDLE FLOW ==================\n",
    "        # Consists of 16 identical blocks. Dilation rate is controlled by output_stride.\n",
    "        middle_blocks = []\n",
    "        for i in range(16):\n",
    "            middle_blocks.append(\n",
    "                Block(in_channels=728, out_channels=728, stride=1, dilation=middle_block_dilation)\n",
    "            )\n",
    "        self.middle_flow = nn.Sequential(*middle_blocks)\n",
    "\n",
    "        # =================== EXIT FLOW ===================\n",
    "        self.exit_block1 = Block(\n",
    "            in_channels=728, \n",
    "            out_channels=1024, \n",
    "            stride=1, \n",
    "            dilation=exit_block_dilations[0]\n",
    "        )\n",
    "        self.exit_block2 = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            SeparableConv2d(1024, 1536, 3, stride=1, padding=exit_block_dilations[1], dilation=exit_block_dilations[1], bias=False),\n",
    "            nn.BatchNorm2d(1536),\n",
    "            nn.ReLU(),\n",
    "            SeparableConv2d(1536, 2048, 3, stride=1, padding=exit_block_dilations[1], dilation=exit_block_dilations[1], bias=False),\n",
    "            nn.BatchNorm2d(2048),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Defines the forward pass of the Xception backbone.\n",
    "\n",
    "        Returns a tuple of feature maps:\n",
    "        - low_level_features: Features from the entry flow for the decoder.\n",
    "        - x: The final high-level features from the exit flow.\n",
    "        \"\"\"\n",
    "        # --- Entry Flow ---\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        # No relu here, as the Block starts with a ReLU\n",
    "        \n",
    "        x = self.block1(x)\n",
    "        # --- The point to extract low-level features ---\n",
    "        # These features have a larger spatial size and contain finer details.\n",
    "        # They will be used in the DeepLabv3+ decoder.\n",
    "        low_level_features = x\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "\n",
    "        # --- Middle Flow ---\n",
    "        x = self.middle_flow(x)\n",
    "\n",
    "        # --- Exit Flow ---\n",
    "        x = self.exit_block1(x)\n",
    "        x = self.exit_block2(x)\n",
    "\n",
    "        return x, low_level_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bb59278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Assuming all previous classes are defined)\n",
    "\n",
    "class _ASPPConv(nn.Module):\n",
    "    \"\"\"A single convolution branch in the ASPP module.\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, dilation):\n",
    "        super(_ASPPConv, self).__init__()\n",
    "        self.module = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, \n",
    "                      padding=dilation, dilation=dilation, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.module(x)\n",
    "\n",
    "class _ASPPPooling(nn.Module):\n",
    "    \"\"\"The image-level pooling branch in the ASPP module.\"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(_ASPPPooling, self).__init__()\n",
    "        self.module = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)), # Pool to a 1x1 feature map\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Get the size of the input feature map\n",
    "        size = x.shape[2:]\n",
    "        # Apply the pooling and convolutions\n",
    "        x = self.module(x)\n",
    "        # Upsample back to the original size\n",
    "        x = F.interpolate(x, size=size, mode='bilinear', align_corners=False)\n",
    "        return x\n",
    "\n",
    "class ASPP(nn.Module):\n",
    "    \"\"\"\n",
    "    Implements Atrous Spatial Pyramid Pooling (ASPP) as described in DeepLabv3.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, output_stride):\n",
    "        super(ASPP, self).__init__()\n",
    "\n",
    "        # Determine dilation rates based on the output stride from the backbone\n",
    "        if output_stride == 16:\n",
    "            dilations = [1, 6, 12, 18]\n",
    "        elif output_stride == 8:\n",
    "            dilations = [1, 12, 24, 36]\n",
    "        else:\n",
    "            raise ValueError(\"Output stride must be 8 or 16.\")\n",
    "\n",
    "        # Number of channels for each of the parallel branches\n",
    "        aspp_out_channels = 256\n",
    "\n",
    "        # --- Branch 1: 1x1 Convolution ---\n",
    "        self.conv1x1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, aspp_out_channels, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(aspp_out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        # --- Branch 2, 3, 4: Atrous Convolutions ---\n",
    "        self.conv_d6 = _ASPPConv(in_channels, aspp_out_channels, dilations[1])\n",
    "        self.conv_d12 = _ASPPConv(in_channels, aspp_out_channels, dilations[2])\n",
    "        self.conv_d18 = _ASPPConv(in_channels, aspp_out_channels, dilations[3])\n",
    "\n",
    "        # --- Branch 5: Image Pooling ---\n",
    "        self.image_pool = _ASPPPooling(in_channels, aspp_out_channels)\n",
    "\n",
    "        # --- Fusion Layer ---\n",
    "        # Concatenates the outputs of all branches and fuses them\n",
    "        self.project = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=aspp_out_channels * 5, # 5 branches\n",
    "                out_channels=aspp_out_channels, \n",
    "                kernel_size=1, \n",
    "                bias=False\n",
    "            ),\n",
    "            nn.BatchNorm2d(aspp_out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass for the ASPP module.\n",
    "        \"\"\"\n",
    "        # Pass the input through each parallel branch\n",
    "        res1 = self.conv1x1(x)\n",
    "        res2 = self.conv_d6(x)\n",
    "        res3 = self.conv_d12(x)\n",
    "        res4 = self.conv_d18(x)\n",
    "        res5 = self.image_pool(x)\n",
    "\n",
    "        # Concatenate the results along the channel dimension (dim=1)\n",
    "        # [B, C1, H, W], [B, C2, H, W], ... -> [B, C1+C2+..., H, W]\n",
    "        x_concat = torch.cat([res1, res2, res3, res4, res5], dim=1)\n",
    "\n",
    "        # Fuse the concatenated features with the final projection layer\n",
    "        x_fused = self.project(x_concat)\n",
    "        \n",
    "        return x_fused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb16c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Assuming all previous classes: SeparableConv2d, Block, Xception, ASPP are defined)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    \"\"\"\n",
    "    The decoder module for DeepLabv3+. It upsamples features from the ASPP module\n",
    "    and fuses them with low-level features from the backbone.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes, low_level_in_channels):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        # --- Low-level Feature Processing ---\n",
    "        # A 1x1 convolution to reduce the number of channels from the backbone's\n",
    "        # low-level features. This is a crucial step for efficiency.\n",
    "        self.conv1x1_low_level = nn.Sequential(\n",
    "            nn.Conv2d(low_level_in_channels, 48, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(48),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        # --- High-level and Fused Feature Processing ---\n",
    "        # Convolutions to refine the features after concatenation.\n",
    "        self.conv3x3_fused = nn.Sequential(\n",
    "            # Using SeparableConv2d is more in line with the Xception theme\n",
    "            SeparableConv2d(256 + 48, 256, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            SeparableConv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        # --- Final Classifier ---\n",
    "        # A final convolution to produce the logits for each class.\n",
    "        self.classifier = nn.Conv2d(256, num_classes, kernel_size=1)\n",
    "\n",
    "\n",
    "    def forward(self, x_high_level: torch.Tensor, x_low_level: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass for the decoder.\n",
    "\n",
    "        Args:\n",
    "            x_high_level (torch.Tensor): High-level features from the ASPP module.\n",
    "            x_low_level (torch.Tensor): Low-level features from the backbone's entry flow.\n",
    "        \"\"\"\n",
    "        # 1. Upsample the high-level features (from ASPP)\n",
    "        # We need to upsample them to match the spatial dimensions of the low-level features.\n",
    "        # Typically, low-level features are at 1/4 size, high-level are at 1/16 or 1/8.\n",
    "        # So we upsample by a factor of 4.\n",
    "        x_high_upsampled = F.interpolate(x_high_level, size=x_low_level.shape[2:], \n",
    "                                         mode='bilinear', align_corners=False)\n",
    "\n",
    "        # 2. Process the low-level features\n",
    "        x_low_processed = self.conv1x1_low_level(x_low_level)\n",
    "\n",
    "        # 3. Concatenate the two feature maps\n",
    "        x_fused = torch.cat([x_high_upsampled, x_low_processed], dim=1)\n",
    "\n",
    "        # 4. Refine the fused features\n",
    "        x_refined = self.conv3x3_fused(x_fused)\n",
    "        \n",
    "        # 5. Get class predictions\n",
    "        x_logits = self.classifier(x_refined)\n",
    "\n",
    "        return x_logits\n",
    "\n",
    "\n",
    "class DeepLabv3_plus(nn.Module):\n",
    "    \"\"\"\n",
    "    The complete DeepLabv3+ model with a modified Xception backbone.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes, output_stride=16, in_channels=3):\n",
    "        super(DeepLabv3_plus, self).__init__()\n",
    "        \n",
    "        # --- Encoder ---\n",
    "        self.backbone = Xception(in_channels=in_channels, output_stride=output_stride)\n",
    "        # The input channels to ASPP is the output channels of the backbone's exit flow\n",
    "        aspp_in_channels = 2048\n",
    "        self.aspp = ASPP(in_channels=aspp_in_channels, output_stride=output_stride)\n",
    "\n",
    "        # --- Decoder ---\n",
    "        # The low-level input channels to the decoder is the output of block1 in the backbone\n",
    "        low_level_in_channels = 128\n",
    "        self.decoder = Decoder(num_classes=num_classes, low_level_in_channels=low_level_in_channels)\n",
    "\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass for the entire DeepLabv3+ model.\n",
    "        \"\"\"\n",
    "        # Get the original input size for final upsampling\n",
    "        input_size = x.shape[2:]\n",
    "\n",
    "        # --- Encoder Pass ---\n",
    "        # 1. Pass through the backbone to get high and low level features\n",
    "        x_high, x_low = self.backbone(x)\n",
    "        \n",
    "        # 2. Pass high-level features through ASPP\n",
    "        x_high = self.aspp(x_high)\n",
    "\n",
    "        # --- Decoder Pass ---\n",
    "        # 3. Pass both feature maps to the decoder\n",
    "        x = self.decoder(x_high, x_low)\n",
    "\n",
    "        # --- Final Upsampling ---\n",
    "        # 4. Upsample the final logits to the original image size\n",
    "        x = F.interpolate(x, size=input_size, mode='bilinear', align_corners=False)\n",
    "\n",
    "        return x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
