{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG-19 Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import FakeData # Using FakeData for demonstration\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. Define VGG-19 Architecture (Configuration E) ---\n",
    "\n",
    "# VGG configuration dictionary (channels per layer, 'M' for MaxPool)\n",
    "# Configuration E: 19 weight layers (16 conv + 3 FC)\n",
    "vgg19_config = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M']\n",
    "\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self, features, num_classes=1000, init_weights=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            features (nn.Module): The convolutional feature extractor block.\n",
    "            num_classes (int): Number of output classes. Default is 1000 for ImageNet.\n",
    "            init_weights (bool): If True, initialize weights.\n",
    "        \"\"\"\n",
    "        super(VGG, self).__init__()\n",
    "        self.features = features\n",
    "        # AdaptiveAvgPool2d maps the variable spatial size output of features\n",
    "        # to a fixed size (7x7) before the classifier. This makes the model\n",
    "        # more flexible to input sizes, although the paper trained on fixed 224x224.\n",
    "        # VGG originally uses fixed-size input and flattening.\n",
    "        # Let's stick closer to the paper's implied flattening for 224x224 input.\n",
    "        # The output size after 5 maxpools from 224x224 is 224 / (2^5) = 7.\n",
    "        # So the input to the classifier is 512 * 7 * 7.\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((7, 7)) # Ensures 7x7 output for classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(p=0.5), # Dropout specified in paper for first two FC layers\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "        if init_weights:\n",
    "            self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x) # Use AdaptiveAvgPool2d to ensure 7x7 spatial size\n",
    "        x = torch.flatten(x, 1) # Flatten the features\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                # Kaiming He initialization for ReLU non-linearity\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d): # Although VGG doesn't use BN by default\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                # Normal distribution initialization for linear layers\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "def make_layers(cfg, batch_norm=False):\n",
    "    \"\"\"Builds the feature extractor layers based on the configuration.\"\"\"\n",
    "    layers = []\n",
    "    in_channels = 3 # Input is RGB\n",
    "    for v in cfg:\n",
    "        if v == 'M':\n",
    "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "        else:\n",
    "            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
    "            if batch_norm:\n",
    "                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
    "            else:\n",
    "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "            in_channels = v\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "def vgg19(num_classes=1000, init_weights=True):\n",
    "    \"\"\"Creates a VGG-19 model instance.\"\"\"\n",
    "    # Note: The original VGG paper did not use Batch Normalization.\n",
    "    # Setting batch_norm=False to be faithful to the paper.\n",
    "    features = make_layers(vgg19_config, batch_norm=False)\n",
    "    model = VGG(features, num_classes=num_classes, init_weights=init_weights)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Data Loading and Augmentation ---\n",
    "\n",
    "# Define image size and standard ImageNet normalization constants\n",
    "IMAGE_SIZE = 224\n",
    "# Paper only mentions mean subtraction, but std normalization is standard practice\n",
    "IMG_MEAN = [0.485, 0.456, 0.406]\n",
    "IMG_STD = [0.229, 0.224, 0.225]\n",
    "NUM_CLASSES = 1000 # For ImageNet (adjust if using a different dataset)\n",
    "\n",
    "# Data augmentation and normalization for training\n",
    "# Following the paper's description + standard practices:\n",
    "# - RandomResizedCrop implies scale jittering (S sampled implicitly) + random crop\n",
    "# - RandomHorizontalFlip\n",
    "# - ColorJitter (approximation of paper's PCA color shift)\n",
    "# - ToTensor\n",
    "# - Normalize\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(IMAGE_SIZE, scale=(0.08, 1.0)), # Includes scale jittering\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1), # Simpler color augmentation\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=IMG_MEAN, std=IMG_STD)\n",
    "])\n",
    "\n",
    "# Just normalization for validation/testing (center crop)\n",
    "# Paper's test scale Q isn't explicitly defined for the simple test here.\n",
    "# Using 256 resizing then 224 center crop is standard practice.\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(IMAGE_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=IMG_MEAN, std=IMG_STD)\n",
    "])\n",
    "\n",
    "# --- Using FakeData ---\n",
    "# Replace with actual dataset (e.g., ImageFolder) for real training\n",
    "# Example using ImageFolder:\n",
    "# data_dir = '/path/to/imagenet'\n",
    "# train_dataset = torchvision.datasets.ImageFolder(os.path.join(data_dir, 'train'), train_transform)\n",
    "# val_dataset = torchvision.datasets.ImageFolder(os.path.join(data_dir, 'val'), test_transform)\n",
    "# test_dataset = torchvision.datasets.ImageFolder(os.path.join(data_dir, 'val'), test_transform) # Often use val set for testing if test labels unavailable\n",
    "\n",
    "print(\"Using FakeData for demonstration purposes...\")\n",
    "# Create dummy datasets\n",
    "train_dataset = FakeData(size=50000, image_size=(3, IMAGE_SIZE, IMAGE_SIZE), num_classes=NUM_CLASSES, transform=train_transform)\n",
    "val_dataset = FakeData(size=10000, image_size=(3, IMAGE_SIZE, IMAGE_SIZE), num_classes=NUM_CLASSES, transform=test_transform)\n",
    "test_dataset = FakeData(size=10000, image_size=(3, IMAGE_SIZE, IMAGE_SIZE), num_classes=NUM_CLASSES, transform=test_transform)\n",
    "\n",
    "# --- DataLoaders ---\n",
    "BATCH_SIZE = 64 # Paper uses 256, adjust based on GPU memory\n",
    "NUM_WORKERS = 4 # Adjust based on system capabilities\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "dataloaders = {'train': train_loader, 'val': val_loader}\n",
    "dataset_sizes = {'train': len(train_dataset), 'val': len(val_dataset)}\n",
    "\n",
    "# Check device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# --- 3. Training Loop ---\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=74):\n",
    "    \"\"\"Trains the model.\"\"\"\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "\n",
    "    print(f\"Starting training for {num_epochs} epochs...\")\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'\\nEpoch {epoch+1}/{num_epochs}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            running_top5_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            num_batches = len(dataloaders[phase])\n",
    "            for i, (inputs, labels) in enumerate(dataloaders[phase]):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward\n",
    "                # Track history only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # Backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # Statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "                # Calculate Top-5 accuracy\n",
    "                _, top5_preds = torch.topk(outputs, 5, dim=1)\n",
    "                # Check if the true label is within the top 5 predictions\n",
    "                top5_correct = torch.sum(top5_preds == labels.data.view(-1, 1).expand_as(top5_preds))\n",
    "                running_top5_corrects += top5_correct\n",
    "\n",
    "                # Print progress\n",
    "                if (i + 1) % 100 == 0 or (i + 1) == num_batches:\n",
    "                   print(f'\\r{phase} Batch {i+1}/{num_batches} Loss: {loss.item():.4f}', end='')\n",
    "\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            epoch_top5_acc = running_top5_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print(f'\\n{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f} Top-5 Acc: {epoch_top5_acc:.4f}')\n",
    "\n",
    "            history[f'{phase}_loss'].append(epoch_loss)\n",
    "            history[f'{phase}_acc'].append(epoch_acc.item()) # Store as float\n",
    "\n",
    "            # Deep copy the model if best val accuracy achieved\n",
    "            if phase == 'val':\n",
    "                 # Adjust learning rate based on validation loss/accuracy\n",
    "                 # ReduceLROnPlateau steps based on metric (e.g., val_acc)\n",
    "                 if isinstance(scheduler, lr_scheduler.ReduceLROnPlateau):\n",
    "                     scheduler.step(epoch_acc) # or scheduler.step(epoch_loss)\n",
    "                 # For StepLR or others, step happens regardless\n",
    "                 elif scheduler is not None:\n",
    "                      scheduler.step()\n",
    "\n",
    "                 current_lr = optimizer.param_groups[0]['lr']\n",
    "                 print(f\"Current Learning Rate: {current_lr:.6f}\")\n",
    "\n",
    "                 if epoch_acc > best_acc:\n",
    "                    best_acc = epoch_acc\n",
    "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                    print(f\"*** Best val Acc: {best_acc:.4f} achieved, saving model... ***\")\n",
    "                    # Save checkpoint\n",
    "                    torch.save({\n",
    "                        'epoch': epoch,\n",
    "                        'model_state_dict': best_model_wts,\n",
    "                        'optimizer_state_dict': optimizer.state_dict(),\n",
    "                        'scheduler_state_dict': scheduler.state_dict() if scheduler else None,\n",
    "                        'best_val_acc': best_acc,\n",
    "                        'history': history,\n",
    "                    }, 'vgg19_best_checkpoint.pth')\n",
    "\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'\\nTraining complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "    # Load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, history\n",
    "\n",
    "# --- Setup Model, Loss, Optimizer, Scheduler ---\n",
    "\n",
    "# Create VGG-19 model instance\n",
    "model = vgg19(num_classes=NUM_CLASSES)\n",
    "model = model.to(device)\n",
    "\n",
    "# If multiple GPUs are available, wrap the model with DataParallel\n",
    "if torch.cuda.device_count() > 1:\n",
    "  print(f\"Using {torch.cuda.device_count()} GPUs!\")\n",
    "  model = nn.DataParallel(model)\n",
    "\n",
    "\n",
    "# Loss Function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer (as described in the paper)\n",
    "# Learning rate = 0.01, momentum = 0.9, weight decay = 5e-4\n",
    "INITIAL_LR = 0.01\n",
    "MOMENTUM = 0.9\n",
    "WEIGHT_DECAY = 5e-4\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=INITIAL_LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "# Learning Rate Scheduler (as described in the paper)\n",
    "# Decrease LR by a factor of 10 when validation accuracy stops improving.\n",
    "# ReduceLROnPlateau is suitable for this.\n",
    "# 'patience': number of epochs with no improvement after which LR is reduced.\n",
    "# 'factor': factor by which the learning rate will be reduced (0.1 for 10x).\n",
    "lr_scheduler_plateau = lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=5, verbose=True)\n",
    "\n",
    "# Alternative: StepLR if you want to decrease at fixed epochs\n",
    "# The paper mentions decreasing LR 3 times over 74 epochs.\n",
    "# e.g., steps could be around epoch 30, 50, 65.\n",
    "# lr_scheduler_step = lr_scheduler.StepLR(optimizer, step_size=25, gamma=0.1)\n",
    "\n",
    "\n",
    "# Select the scheduler to use\n",
    "# Using ReduceLROnPlateau as it directly matches the paper's description\n",
    "scheduler = lr_scheduler_plateau\n",
    "# scheduler = lr_scheduler_step # Uncomment to use StepLR instead\n",
    "\n",
    "# --- Start Training ---\n",
    "# Warning: This will take a very long time on FakeData or real data without GPUs.\n",
    "# Setting num_epochs to a small number for demonstration.\n",
    "NUM_EPOCHS_DEMO = 5 # Set to 74 for full training attempt\n",
    "print(\"Starting dummy training run for demonstration...\")\n",
    "trained_model, training_history = train_model(model, criterion, optimizer, scheduler, num_epochs=NUM_EPOCHS_DEMO)\n",
    "print(\"Dummy training finished.\")\n",
    "\n",
    "# You can plot training history (loss/accuracy curves) using matplotlib here\n",
    "# e.g., plt.plot(training_history['train_acc'], label='train_acc') ...\n",
    "\n",
    "# --- 4. Testing Procedure ---\n",
    "\n",
    "def test_model(model, test_loader):\n",
    "    \"\"\"Evaluates the model on the test set.\"\"\"\n",
    "    model.eval()  # Set model to evaluate mode\n",
    "    running_corrects = 0\n",
    "    running_top5_corrects = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    print(\"\\nStarting testing...\")\n",
    "    since = time.time()\n",
    "\n",
    "    # Iterate over data.\n",
    "    with torch.no_grad(): # No gradients needed for testing\n",
    "        for i, (inputs, labels) in enumerate(test_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            # Statistics\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "            # Top-5 Accuracy\n",
    "            _, top5_preds = torch.topk(outputs, 5, dim=1)\n",
    "            top5_correct = torch.sum(top5_preds == labels.data.view(-1, 1).expand_as(top5_preds))\n",
    "            running_top5_corrects += top5_correct\n",
    "\n",
    "            if (i + 1) % 50 == 0 :\n",
    "                print(f'\\rTest Batch {i+1}/{len(test_loader)}', end='')\n",
    "\n",
    "\n",
    "    test_acc = running_corrects.double() / total_samples\n",
    "    test_top5_acc = running_top5_corrects.double() / total_samples\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'\\nTesting complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Test Accuracy (Top-1): {test_acc:.4f}')\n",
    "    print(f'Test Accuracy (Top-5): {test_top5_acc:.4f}')\n",
    "    return test_acc.item(), test_top5_acc.item()\n",
    "\n",
    "# --- Run Testing ---\n",
    "# Ensure the best model weights are loaded if you stopped and restarted\n",
    "# If 'trained_model' holds the best weights from train_model, use it directly.\n",
    "# Otherwise, load from checkpoint:\n",
    "# checkpoint = torch.load('vgg19_best_checkpoint.pth')\n",
    "# model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "print(\"\\nEvaluating the best model on the test set...\")\n",
    "# Use the model returned by train_model which should have the best weights loaded\n",
    "test_acc_top1, test_acc_top5 = test_model(trained_model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
